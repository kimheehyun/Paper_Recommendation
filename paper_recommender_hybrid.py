<<<<<<< HEAD
import streamlit as st
import arxiv
import requests
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd
from datetime import datetime
from groq import Groq
import os
import time
from deep_translator import GoogleTranslator

# ========================================
# ë²ˆì—­ í•¨ìˆ˜ (í•œêµ­ì–´ â†’ ì˜ì–´)
# ========================================
def to_english(text: str) -> str:
    """ìë™ ê°ì§€ í›„ ì˜ì–´ë¡œ ë²ˆì—­. ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜"""
    try:
        return GoogleTranslator(source="auto", target="en").translate(text)
    except Exception:
        return text

# ========================================
# Groq API ì„¤ì •
# ========================================
groq_api_key = st.secrets.get("GROQ_API_KEY", os.getenv("GROQ_API_KEY"))
client = Groq(api_key=groq_api_key)

# ========================================
# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° í˜ì´ì§€ ì„¤ì •
# ========================================
st.set_page_config(page_title="ë…¼ë¬¸ ì¶”ì²œ ì±—ë´‡", layout="wide")
st.title("ë…¼ë¬¸ ì¶”ì²œ ì±—ë´‡")
st.write("arXiv + Semantic Scholar Co-Citationì„ í™œìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë…¼ë¬¸ ì¶”ì²œ ì„œë¹„ìŠ¤")

@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2", device="cpu")

model = load_model()

# ========================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ========================================
if "messages" not in st.session_state:
    st.session_state.messages = []
if "papers_cache" not in st.session_state:
    st.session_state.papers_cache = {}
if "last_papers" not in st.session_state:
    st.session_state.last_papers = None
if "last_scores" not in st.session_state:
    st.session_state.last_scores = None
if "last_semantic_sim" not in st.session_state:
    st.session_state.last_semantic_sim = None
if "last_citations" not in st.session_state:
    st.session_state.last_citations = None
if "last_recency" not in st.session_state:
    st.session_state.last_recency = None
if "last_co_citation" not in st.session_state:
    st.session_state.last_co_citation = None
if "last_explanation" not in st.session_state:
    st.session_state.last_explanation = None

# ========================================
# arXiv ë…¼ë¬¸ ê°€ì ¸ì˜¤ê¸°
# ========================================
def fetch_arxiv_papers(query, max_results=50):
    """max_resultsë¥¼ 50ìœ¼ë¡œ ì¦ê°€ (2ë‹¨ê³„ í•„í„°ë§ì„ ìœ„í•´)"""
    try:
        client_arxiv = arxiv.Client()
        search = arxiv.Search(
            query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance
        )
        papers = list(client_arxiv.results(search))
        df = pd.DataFrame(
            {
                "title": [p.title for p in papers],
                "abstract": [p.summary if p.summary else "" for p in papers],
                "arxiv_id": [p.entry_id.split("/abs/")[-1] for p in papers],
                "doi": [p.doi if p.doi else "" for p in papers],
                "published": [p.published.strftime("%Y-%m-%d") for p in papers],
                "authors": [
                    ", ".join([author.name for author in p.authors[:3]]) for p in papers
                ],
            }
        )
        return df
    except Exception as e:
        st.error(f"arXiv ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

# ========================================
# Semantic Scholar ì •ë³´ ê°€ì ¸ì˜¤ê¸°
# ========================================
def fetch_semanticscholar_info(title, arxiv_id):
    cache_key = title + "_" + arxiv_id
    if cache_key in st.session_state.papers_cache:
        return st.session_state.papers_cache[cache_key]

    default_result = {
        "paper_id": "",
        "citation_count": 0,
        "influential_citation_count": 0,
        "publication_date": "",
        "found_by": "not_found"
    }

    def search_ss(query_type, query_value):
        try:
            if query_type == "title":
                url = "https://api.semanticscholar.org/graph/v1/paper/search"
                params = {
                    "query": query_value,
                    "limit": 1,
                    "fields": "paperId,citationCount,influentialCitationCount,publicationDate,title"
                }
                res = requests.get(url, params=params, timeout=5)
                if res.status_code == 200:
                    data = res.json()
                    if data.get("data") and len(data["data"]) > 0:
                        paper = data["data"][0]
                        return paper, "title"

            elif query_type == "arxiv_id":
                paper_id = f"ARXIV:{query_value}"
                url_id = f"https://api.semanticscholar.org/graph/v1/paper/{paper_id}"
                params_id = {
                    "fields": "paperId,citationCount,influentialCitationCount,publicationDate,title"
                }
                res = requests.get(url_id, params=params_id, timeout=5)
                if res.status_code == 200:
                    paper = res.json()
                    if paper.get("paperId"): 
                        return paper, "arxiv_id"
        except Exception:
            return None, None
        return None, None

    paper_info, found_by = search_ss("title", title)
    
    if not paper_info and arxiv_id:
        paper_info, found_by = search_ss("arxiv_id", arxiv_id)

    if paper_info:
        result = {
            "paper_id": paper_info.get("paperId", ""),
            "citation_count": paper_info.get("citationCount", 0),
            "influential_citation_count": paper_info.get("influentialCitationCount", 0),
            "publication_date": paper_info.get("publicationDate", ""),
            "found_by": found_by
        }
        st.session_state.papers_cache[cache_key] = result
        time.sleep(0.15)  # API ì œí•œ ì™„í™”
        return result
    
    st.session_state.papers_cache[cache_key] = default_result
    return default_result

# ========================================
# íŠ¹ì • ë…¼ë¬¸ì˜ citations ê°€ì ¸ì˜¤ê¸° (ê°œì„ : ì—ëŸ¬ í•¸ë“¤ë§ + ì¬ì‹œë„)
# ========================================
def fetch_paper_citations(paper_id, limit=100, max_retries=2):
    """
    íŠ¹ì • ë…¼ë¬¸ì„ ì¸ìš©í•œ ë…¼ë¬¸ì˜ ID ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
    """
    if not paper_id:
        return []
    
    for attempt in range(max_retries):
        try:
            url = f"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations"
            params = {
                "fields": "paperId",
                "limit": limit
            }
            res = requests.get(url, params=params, timeout=8)
            
            if res.status_code == 200:
                data = res.json()
                citing_papers = []
                for item in data.get("data", []):
                    citing_paper = item.get("citingPaper", {})
                    if citing_paper.get("paperId"):
                        citing_papers.append(citing_paper["paperId"])
                
                time.sleep(0.2)  # API ì œí•œ ì™„í™”
                return citing_papers
                
            elif res.status_code == 429:  # Too Many Requests
                wait_time = (attempt + 1) * 2
                time.sleep(wait_time)
                continue
                
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(1)
                continue
            
    return []

# ========================================
# ê³µë™ì¸ìš© ì ìˆ˜ ê³„ì‚° (ê°œì„ ë²„ì „)
# ========================================
def build_co_citation_scores(paper_ids, limit=100, similarity_metric="jaccard", seed_window=5):
    """
    ê°œì„ ëœ ê³µë™ì¸ìš© ì ìˆ˜ ê³„ì‚°
    - API í˜¸ì¶œ ìµœì†Œí™”
    - ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
    - ì§„í–‰ìƒí™© í‘œì‹œ
    """
    if not paper_ids:
        return np.zeros(len(paper_ids))

    # 1ë‹¨ê³„: ì‹œë“œ ë…¼ë¬¸ ì„ ì • (ìœ íš¨í•œ paper_idê°€ ìˆëŠ” ìƒìœ„ Nê°œ)
    valid_seed_indices = []
    for idx, pid in enumerate(paper_ids[:seed_window]):
        if pid:
            valid_seed_indices.append(idx)
    
    if not valid_seed_indices:
        st.warning("âš ï¸ ìœ íš¨í•œ ì‹œë“œ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê³µë™ì¸ìš© ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return np.zeros(len(paper_ids))
    
    # 2ë‹¨ê³„: ì‹œë“œ ë…¼ë¬¸ë“¤ì˜ ì¸ìš© ì •ë³´ë§Œ ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œ ìµœì†Œí™”)
    st.info(f"ğŸ” {len(valid_seed_indices)}ê°œ ì‹œë“œ ë…¼ë¬¸ì˜ ì¸ìš© ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘...")
    seed_citation_sets = []
    
    for idx in valid_seed_indices:
        pid = paper_ids[idx]
        citations = fetch_paper_citations(pid, limit=limit)
        
        if citations:
            seed_citation_sets.append(set(citations))
            st.caption(f"   âœ“ ì‹œë“œ ë…¼ë¬¸ {idx+1}: {len(citations)}ê°œ ì¸ìš© ë°œê²¬")
        else:
            seed_citation_sets.append(set())
            st.caption(f"   âœ— ì‹œë“œ ë…¼ë¬¸ {idx+1}: ì¸ìš© ì •ë³´ ì—†ìŒ")
    
    # ëª¨ë“  ì‹œë“œì˜ ì¸ìš© ì§‘í•©ì´ ë¹„ì–´ìˆìœ¼ë©´ ì¢…ë£Œ
    if all(len(s) == 0 for s in seed_citation_sets):
        st.warning("âš ï¸ ì‹œë“œ ë…¼ë¬¸ë“¤ì˜ ì¸ìš© ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ê³µë™ì¸ìš© ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return np.zeros(len(paper_ids))
    
    # 3ë‹¨ê³„: ëª¨ë“  í›„ë³´ ë…¼ë¬¸ì˜ ì¸ìš© ì •ë³´ ìˆ˜ì§‘
    st.info(f"ğŸ” {len(paper_ids)}ê°œ í›„ë³´ ë…¼ë¬¸ì˜ ì¸ìš© ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘...")
    all_citation_sets = []
    
    for idx, pid in enumerate(paper_ids):
        if pid:
            # ì‹œë“œ ë…¼ë¬¸ì€ ì´ë¯¸ ìˆ˜ì§‘í–ˆìœ¼ë¯€ë¡œ ì¬ì‚¬ìš©
            if idx in valid_seed_indices:
                seed_idx = valid_seed_indices.index(idx)
                all_citation_sets.append(seed_citation_sets[seed_idx])
            else:
                citations = fetch_paper_citations(pid, limit=limit)
                all_citation_sets.append(set(citations) if citations else set())
        else:
            all_citation_sets.append(set())
        
        # ì§„í–‰ìƒí™© í‘œì‹œ (10ê°œë§ˆë‹¤)
        if (idx + 1) % 10 == 0:
            st.caption(f"   ì²˜ë¦¬ ì¤‘: {idx+1}/{len(paper_ids)}")
    
    # 4ë‹¨ê³„: ê° í›„ë³´ ë…¼ë¬¸ê³¼ ì‹œë“œ ë…¼ë¬¸ë“¤ ê°„ì˜ ê³µë™ì¸ìš© ìœ ì‚¬ë„ ê³„ì‚°
    scores = []
    
    for i in range(len(paper_ids)):
        candidate_set = all_citation_sets[i]
        
        if not candidate_set:
            scores.append(0.0)
            continue
        
        # ì‹œë“œ ë…¼ë¬¸ë“¤ê³¼ì˜ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for seed_idx in valid_seed_indices:
            if seed_idx == i:  # ìê¸° ìì‹ ì€ ì œì™¸
                continue
                
            seed_set = all_citation_sets[seed_idx]
            if not seed_set:
                continue
            
            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            intersection = len(candidate_set & seed_set)
            union = len(candidate_set | seed_set)
            
            if union > 0:
                if similarity_metric == "cosine":
                    sim = intersection / np.sqrt(len(candidate_set) * len(seed_set))
                else:  # jaccard
                    sim = intersection / union
                similarities.append(sim)
        
        # í‰ê·  ìœ ì‚¬ë„
        avg_sim = float(np.mean(similarities)) if similarities else 0.0
        scores.append(avg_sim)
    
    # 5ë‹¨ê³„: ì •ê·œí™” (0-1 ë²”ìœ„)
    scores = np.array(scores)
    max_score = scores.max()
    
    if max_score > 0:
        scores = scores / max_score
        st.success(f"âœ“ ê³µë™ì¸ìš© ë¶„ì„ ì™„ë£Œ! (ìµœëŒ€ ìœ ì‚¬ë„: {max_score:.4f})")
    else:
        st.warning("âš ï¸ ìœ ì˜ë¯¸í•œ ê³µë™ì¸ìš© íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    return scores

# ========================================
# ì¶”ì²œ ì ìˆ˜ ê³„ì‚° (2ë‹¨ê³„ í•„í„°ë§ ë°©ì‹)
# ========================================
def calculate_recommendation_score(papers_df, query_embedding, top_n=10, use_two_stage=True):
    """
    use_two_stage=True: 50ê°œ ìˆ˜ì§‘ â†’ ì¸ìš© ê¸°ë°˜ í•„í„°ë§ â†’ 15ê°œë¡œ ì••ì¶• â†’ ì •ë°€ ë¶„ì„
    use_two_stage=False: ê¸°ì¡´ ë°©ì‹ (30ê°œ ëª¨ë‘ ë¶„ì„)
    """
    papers_df = papers_df.copy()
    papers_df["abstract"] = papers_df["abstract"].fillna("").astype(str)
    
    # ì„ë² ë”© ê³„ì‚°
    texts = papers_df["title"].astype(str) + ". " + papers_df["abstract"].astype(str)
    embeddings = model.encode(texts.tolist())
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    semantic_scores = cosine_similarity([query_embedding], embeddings)[0]
    
    # ============================================================
    # 1ë‹¨ê³„: ë¹ ë¥¸ í•„í„°ë§ (ì¸ìš©ìˆ˜ + ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ë¡œ í›„ë³´ ì••ì¶•)
    # ============================================================
    if use_two_stage and len(papers_df) > 15:
        st.info("ğŸ” 1ë‹¨ê³„: ì¸ìš©ìˆ˜ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§ ì¤‘...")
        
        # Semantic Scholar ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë¹ ë¥¸ í•„í„°ë§ìš©)
        quick_citation_scores = []
        for idx, row in papers_df.iterrows():
            info = fetch_semanticscholar_info(title=row["title"], arxiv_id=row["arxiv_id"])
            citation_count = info["citation_count"]
            quick_citation_scores.append(citation_count)
        
        # ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ + ì¸ìš©ìˆ˜ë¡œ 1ì°¨ ì ìˆ˜ ê³„ì‚°
        quick_citation_scores = np.array(quick_citation_scores)
        normalized_citations = quick_citation_scores / (quick_citation_scores.max() + 1)
        
        normalized_semantic = semantic_scores / (semantic_scores.max() + 0.001)
        
        # 1ì°¨ ì ìˆ˜: ì˜ë¯¸ + ì¸ìš©
        quick_scores = 0.8 * normalized_semantic + 0.2 * normalized_citations
        
        # ìƒìœ„ 15ê°œë§Œ ì„ íƒ (ì •ë°€ ë¶„ì„ ëŒ€ìƒ)
        top_15_idx = np.argsort(quick_scores)[::-1][:15]
        papers_df = papers_df.iloc[top_15_idx].reset_index(drop=True)
        semantic_scores = semantic_scores[top_15_idx]
        embeddings = embeddings[top_15_idx]
        
        st.success(f"âœ“ ìƒìœ„ 15ê°œ í›„ë³´ë¡œ ì••ì¶• ì™„ë£Œ (ì¸ìš©ìˆ˜ ë²”ìœ„: {quick_citation_scores[top_15_idx].min():.0f}~{quick_citation_scores[top_15_idx].max():.0f}íšŒ)")
    
    # ============================================================
    # 2ë‹¨ê³„: ì •ë°€ ë¶„ì„ (ê³µë™ì¸ìš© í¬í•¨)
    # ============================================================
    st.info("ğŸ” 2ë‹¨ê³„: ì •ë°€ ë¶„ì„ ì‹œì‘...")
    
    # Semantic Scholar ì •ë³´ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ í™œìš©)
    citation_scores = []
    recency_scores = []
    ss_info_list = []
    paper_ids = []
    
    for idx, row in papers_df.iterrows():
        info = fetch_semanticscholar_info(title=row["title"], arxiv_id=row["arxiv_id"]) 
        ss_info_list.append(info)
        paper_ids.append(info["paper_id"])
        
        citation_count = info["citation_count"]
        citation_score = min(citation_count / 100, 1.0) if citation_count > 0 else 0
        citation_scores.append(citation_score)
        
        # ìµœì‹ ì„± ì ìˆ˜
        pub_date = datetime.strptime(row["published"], "%Y-%m-%d")
        days_old = (datetime.now() - pub_date).days
        recency_score = max(1 - (days_old / 3650), 0)
        recency_scores.append(recency_score)
    
    # ê³µë™ ì¸ìš© ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
    st.divider()
    co_citation_scores = build_co_citation_scores(
        paper_ids, limit=100, similarity_metric="jaccard", seed_window=5
    )
    
    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
    citation_scores = np.array(citation_scores)
    recency_scores = np.array(recency_scores)
    co_citation_scores = np.array(co_citation_scores)
    
    # semantic_scores ì •ê·œí™”
    if semantic_scores.max() > 0:
        normalized_semantic = semantic_scores / semantic_scores.max()
    else:
        normalized_semantic = semantic_scores
    
    # ìµœì¢… ê°€ì¤‘ì¹˜: ì˜ë¯¸ + ì¸ìš© + ìµœì‹ ì„± + ê³µë™ì¸ìš©
    final_scores = (
        0.70 * normalized_semantic
        + 0.10 * citation_scores
        + 0.10 * recency_scores
        + 0.10 * co_citation_scores
    )
    
    top_idx = np.argsort(final_scores)[::-1][:top_n]
    result_df = papers_df.iloc[top_idx].reset_index(drop=True)
    result_scores = final_scores[top_idx]
    semantic_sim = semantic_scores[top_idx]
    citations = [citation_scores[i] for i in top_idx]
    recency = [recency_scores[i] for i in top_idx]
    co_citation = [co_citation_scores[i] for i in top_idx]
    
    # ê²°ê³¼ì— ì¶”ê°€ ì •ë³´ í¬í•¨
    result_df["citation_count"] = [ss_info_list[i]["citation_count"] for i in top_idx]
    result_df["found_by"] = [ss_info_list[i]["found_by"] for i in top_idx]
    result_df["co_citation_score"] = co_citation
    
    return result_df, result_scores, semantic_sim, citations, recency, co_citation

# ========================================
# LLM ì„¤ëª… ìƒì„±
# ========================================
def generate_recommendation_explanation(user_query, recommended_papers):
    papers_info = ""
    for idx, row in recommended_papers.iterrows():
        co_citation_info = f"\nCo-citation Score: {row.get('co_citation_score', 0):.3f}" if row.get('co_citation_score', 0) > 0 else ""
        
        papers_info += f"\n---\nPaper {idx+1}: {row['title']}\nAuthors: {row['authors']}\nPublished: {row['published']}\nCitations: {row.get('citation_count', 0)}{co_citation_info}\nAbstract: {row['abstract'][:300]}...\n"
    
    prompt = f"""The user is interested in the following field: "{user_query}"

Analyze the abstracts of the recommended papers below. The 'Co-citation Score' reflects how frequently the candidate is cited together with the seed papers across the literature. Provide a concise abstract summary and a professional explanation of why the paper was recommended.

The output MUST be in Korean and strictly follow the format below. Separate the analysis of each paper using the exact phrase: ###END_OF_PAPER_ANALYSIS###

{papers_info}

Format:
- ì´ˆë¡ ìš”ì•½ [N]: [ê°„ë‹¨í•œ ì„¤ëª…] \n
- ë…¼ë¬¸ ì¶”ì²œ ê·¼ê±° [N]: [ê°„ë‹¨í•œ ì„¤ëª…]
###END_OF_PAPER_ANALYSIS###
"""
    
    try:
        message = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1024,
            temperature=0.7,
        )
        return message.choices[0].message.content
    except Exception as e:
        return f"LLM ì„¤ëª… ìƒì„± ì˜¤ë¥˜: {str(e)}"

# ========================================
# ì±—ë´‡ ì…ë ¥ ì²˜ë¦¬
# ========================================
def chat_with_user(user_input):
    # ğŸŸ¢ Step 1. ì…ë ¥ì„ ì˜ì–´ë¡œ ë²ˆì—­
    user_input_en = to_english(user_input)

    with st.spinner("ì§€ê¸ˆ arXivì—ì„œ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        # ğŸŸ¢ Step 2. ì˜ì–´ ë²ˆì—­ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
        papers_df = fetch_arxiv_papers(user_input_en, max_results=50)

    if papers_df.empty:
        response = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì£¼ì œì˜ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.rerun()
        return

    # ğŸŸ¢ Step 3. ì˜ì–´ ì¿¼ë¦¬ë¡œ ì„ë² ë”© ê³„ì‚°
    query_embedding = model.encode(user_input_en)

    with st.spinner("ì§€ê¸ˆ Semantic Scholarì—ì„œ ì¸ìš© ì •ë³´ ë° ê³µë™ì¸ìš© ë¶„ì„ ì¤‘..."):
        rec_papers, scores, semantic_sim, citations, recency, co_citation = (
            calculate_recommendation_score(papers_df, query_embedding, top_n=5)
        )

    with st.spinner("ì§€ê¸ˆ LLMì´ ì¶”ì²œ ì´ìœ ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        explanation = generate_recommendation_explanation(user_input, rec_papers)

    # ğŸŸ¢ Step 4. ì•ˆë‚´ ë¬¸êµ¬ì— ë²ˆì—­ ë‚´ìš© í‘œì‹œ
    response = (
        f"**'{user_input}'** â†’ **'{user_input_en}'**(ì˜ì–´ ë²ˆì—­)ìœ¼ë¡œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\n"
        f"ê´€ë ¨ ì¶”ì²œ ë…¼ë¬¸ {len(rec_papers)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
    )

    st.session_state.messages.append({"role": "assistant", "content": response})

    # ê²°ê³¼ ì €ì¥ ë° í™”ë©´ ê°±ì‹ ì€ ë™ì¼
    st.session_state.last_papers = rec_papers
    st.session_state.last_scores = scores
    st.session_state.last_semantic_sim = semantic_sim
    st.session_state.last_citations = citations
    st.session_state.last_recency = recency
    st.session_state.last_co_citation = co_citation
    st.session_state.last_explanation = explanation

    st.rerun()

# ========================================
# UI ë ˆì´ì•„ì›ƒ
# ========================================

message_count = len(st.session_state.messages)
if message_count > 0:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

user_query = st.chat_input("ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ë‚˜ ë…¼ë¬¸ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

if user_query:
    st.session_state.messages.append({"role": "user", "content": user_query})
    chat_with_user(user_query)

# ìµœì‹  ì¶”ì²œ ë…¼ë¬¸ ìƒì„¸ ì •ë³´
if st.session_state.last_papers is not None and not st.session_state.last_papers.empty:
    rec_papers = st.session_state.last_papers
    scores = st.session_state.last_scores
    semantic_sim = st.session_state.last_semantic_sim
    citations = st.session_state.last_citations
    recency = st.session_state.last_recency
    co_citation = st.session_state.last_co_citation
    
    st.divider()
    st.subheader("ìµœì‹  ì¶”ì²œ ë…¼ë¬¸ ìƒì„¸ ì •ë³´")
    
    for idx, row in rec_papers.iterrows():
        with st.expander(f"**{idx+1}. {row['title']}**"):
            col1, col2 = st.columns([2, 1])
            with col1:
                st.write(f"**ì €ì:** {row['authors']}")
                st.write(f"**ë°œí‘œì¼:** {row['published']}")
                st.write(f"**arXiv ID:** {row['arxiv_id']}")
                if row.get('doi'):
                    st.write(f"**DOI:** {row['doi']}")
                st.write(f"**ì¸ìš©ìˆ˜:** {row.get('citation_count', 0)}íšŒ")
                st.write(f"**ê²€ìƒ‰ë°©ë²•:** {row.get('found_by', 'N/A')}")
                st.write(f"\n**ì´ˆë¡:**\n{row['abstract']}")
            with col2:
                st.metric("ì¶”ì²œ ì ìˆ˜", f"{scores[idx]:.3f}")
                st.metric("ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„", f"{semantic_sim[idx]:.3f}")
                st.metric("ì¸ìš© ê¸°ë°˜ ì ìˆ˜", f"{citations[idx]:.3f}")
                st.metric("ìµœì‹ ì„± ì ìˆ˜", f"{recency[idx]:.3f}")
                st.metric("ê³µë™ ì¸ìš© ì ìˆ˜", f"{co_citation[idx]:.3f}",
                        help="ì‹œë“œ ë…¼ë¬¸ë“¤ê³¼ í•¨ê»˜ ì¸ìš©ë˜ëŠ” ë¹ˆë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°í•œ ìœ ì‚¬ë„ì…ë‹ˆë‹¤.")
            
            paper_url = f"https://arxiv.org/abs/{row['arxiv_id']}"
            st.markdown(f"[arXivì—ì„œ ë³´ê¸°]({paper_url})")

# LLM ë¶„ì„ ê²°ê³¼
if st.session_state.last_explanation:
    st.divider()
    st.subheader("ìµœì‹  LLM ë…¼ë¬¸ ì´ˆë¡ ìš”ì•½ ë° ì¶”ì²œ ë¶„ì„")
    
    analysis_parts = st.session_state.last_explanation.split("###END_OF_PAPER_ANALYSIS###")
    
    for i, part in enumerate(analysis_parts):
        cleaned_part = part.strip()
        if cleaned_part:
            if i > 0:
                st.divider()
=======
import streamlit as st
import arxiv
import requests
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import pandas as pd
from datetime import datetime
from groq import Groq
import os
import time
from deep_translator import GoogleTranslator

# ========================================
# ë²ˆì—­ í•¨ìˆ˜ (í•œêµ­ì–´ â†’ ì˜ì–´)
# ========================================
def to_english(text: str) -> str:
    """ìë™ ê°ì§€ í›„ ì˜ì–´ë¡œ ë²ˆì—­. ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜"""
    try:
        return GoogleTranslator(source="auto", target="en").translate(text)
    except Exception:
        return text

# ========================================
# Groq API ì„¤ì •
# ========================================
groq_api_key = st.secrets.get("GROQ_API_KEY", os.getenv("GROQ_API_KEY"))
client = Groq(api_key=groq_api_key)

# ========================================
# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° í˜ì´ì§€ ì„¤ì •
# ========================================
st.set_page_config(page_title="ë…¼ë¬¸ ì¶”ì²œ ì±—ë´‡", layout="wide")
st.title("ë…¼ë¬¸ ì¶”ì²œ ì±—ë´‡")
st.write("arXiv + Semantic Scholar Co-Citationì„ í™œìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ ë…¼ë¬¸ ì¶”ì²œ ì„œë¹„ìŠ¤")

@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2", device="cpu")

model = load_model()

# ========================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ========================================
if "messages" not in st.session_state:
    st.session_state.messages = []
if "papers_cache" not in st.session_state:
    st.session_state.papers_cache = {}
if "last_papers" not in st.session_state:
    st.session_state.last_papers = None
if "last_scores" not in st.session_state:
    st.session_state.last_scores = None
if "last_semantic_sim" not in st.session_state:
    st.session_state.last_semantic_sim = None
if "last_citations" not in st.session_state:
    st.session_state.last_citations = None
if "last_recency" not in st.session_state:
    st.session_state.last_recency = None
if "last_co_citation" not in st.session_state:
    st.session_state.last_co_citation = None
if "last_explanation" not in st.session_state:
    st.session_state.last_explanation = None

# ========================================
# arXiv ë…¼ë¬¸ ê°€ì ¸ì˜¤ê¸°
# ========================================
def fetch_arxiv_papers(query, max_results=50):
    """max_resultsë¥¼ 50ìœ¼ë¡œ ì¦ê°€ (2ë‹¨ê³„ í•„í„°ë§ì„ ìœ„í•´)"""
    try:
        client_arxiv = arxiv.Client()
        search = arxiv.Search(
            query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance
        )
        papers = list(client_arxiv.results(search))
        df = pd.DataFrame(
            {
                "title": [p.title for p in papers],
                "abstract": [p.summary if p.summary else "" for p in papers],
                "arxiv_id": [p.entry_id.split("/abs/")[-1] for p in papers],
                "doi": [p.doi if p.doi else "" for p in papers],
                "published": [p.published.strftime("%Y-%m-%d") for p in papers],
                "authors": [
                    ", ".join([author.name for author in p.authors[:3]]) for p in papers
                ],
            }
        )
        return df
    except Exception as e:
        st.error(f"arXiv ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")
        return pd.DataFrame()

# ========================================
# Semantic Scholar ì •ë³´ ê°€ì ¸ì˜¤ê¸°
# ========================================
def fetch_semanticscholar_info(title, arxiv_id):
    cache_key = title + "_" + arxiv_id
    if cache_key in st.session_state.papers_cache:
        return st.session_state.papers_cache[cache_key]

    default_result = {
        "paper_id": "",
        "citation_count": 0,
        "influential_citation_count": 0,
        "publication_date": "",
        "found_by": "not_found"
    }

    def search_ss(query_type, query_value):
        try:
            if query_type == "title":
                url = "https://api.semanticscholar.org/graph/v1/paper/search"
                params = {
                    "query": query_value,
                    "limit": 1,
                    "fields": "paperId,citationCount,influentialCitationCount,publicationDate,title"
                }
                res = requests.get(url, params=params, timeout=5)
                if res.status_code == 200:
                    data = res.json()
                    if data.get("data") and len(data["data"]) > 0:
                        paper = data["data"][0]
                        return paper, "title"

            elif query_type == "arxiv_id":
                paper_id = f"ARXIV:{query_value}"
                url_id = f"https://api.semanticscholar.org/graph/v1/paper/{paper_id}"
                params_id = {
                    "fields": "paperId,citationCount,influentialCitationCount,publicationDate,title"
                }
                res = requests.get(url_id, params=params_id, timeout=5)
                if res.status_code == 200:
                    paper = res.json()
                    if paper.get("paperId"): 
                        return paper, "arxiv_id"
        except Exception:
            return None, None
        return None, None

    paper_info, found_by = search_ss("title", title)
    
    if not paper_info and arxiv_id:
        paper_info, found_by = search_ss("arxiv_id", arxiv_id)

    if paper_info:
        result = {
            "paper_id": paper_info.get("paperId", ""),
            "citation_count": paper_info.get("citationCount", 0),
            "influential_citation_count": paper_info.get("influentialCitationCount", 0),
            "publication_date": paper_info.get("publicationDate", ""),
            "found_by": found_by
        }
        st.session_state.papers_cache[cache_key] = result
        time.sleep(0.15)  # API ì œí•œ ì™„í™”
        return result
    
    st.session_state.papers_cache[cache_key] = default_result
    return default_result

# ========================================
# íŠ¹ì • ë…¼ë¬¸ì˜ citations ê°€ì ¸ì˜¤ê¸° (ê°œì„ : ì—ëŸ¬ í•¸ë“¤ë§ + ì¬ì‹œë„)
# ========================================
def fetch_paper_citations(paper_id, limit=100, max_retries=2):
    """
    íŠ¹ì • ë…¼ë¬¸ì„ ì¸ìš©í•œ ë…¼ë¬¸ì˜ ID ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
    """
    if not paper_id:
        return []
    
    for attempt in range(max_retries):
        try:
            url = f"https://api.semanticscholar.org/graph/v1/paper/{paper_id}/citations"
            params = {
                "fields": "paperId",
                "limit": limit
            }
            res = requests.get(url, params=params, timeout=8)
            
            if res.status_code == 200:
                data = res.json()
                citing_papers = []
                for item in data.get("data", []):
                    citing_paper = item.get("citingPaper", {})
                    if citing_paper.get("paperId"):
                        citing_papers.append(citing_paper["paperId"])
                
                time.sleep(0.2)  # API ì œí•œ ì™„í™”
                return citing_papers
                
            elif res.status_code == 429:  # Too Many Requests
                wait_time = (attempt + 1) * 2
                time.sleep(wait_time)
                continue
                
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(1)
                continue
            
    return []

# ========================================
# ê³µë™ì¸ìš© ì ìˆ˜ ê³„ì‚° (ê°œì„ ë²„ì „)
# ========================================
def build_co_citation_scores(paper_ids, limit=100, similarity_metric="jaccard", seed_window=5):
    """
    ê°œì„ ëœ ê³µë™ì¸ìš© ì ìˆ˜ ê³„ì‚°
    - API í˜¸ì¶œ ìµœì†Œí™”
    - ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
    - ì§„í–‰ìƒí™© í‘œì‹œ
    """
    if not paper_ids:
        return np.zeros(len(paper_ids))

    # 1ë‹¨ê³„: ì‹œë“œ ë…¼ë¬¸ ì„ ì • (ìœ íš¨í•œ paper_idê°€ ìˆëŠ” ìƒìœ„ Nê°œ)
    valid_seed_indices = []
    for idx, pid in enumerate(paper_ids[:seed_window]):
        if pid:
            valid_seed_indices.append(idx)
    
    if not valid_seed_indices:
        st.warning("âš ï¸ ìœ íš¨í•œ ì‹œë“œ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê³µë™ì¸ìš© ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return np.zeros(len(paper_ids))
    
    # 2ë‹¨ê³„: ì‹œë“œ ë…¼ë¬¸ë“¤ì˜ ì¸ìš© ì •ë³´ë§Œ ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œ ìµœì†Œí™”)
    st.info(f"ğŸ” {len(valid_seed_indices)}ê°œ ì‹œë“œ ë…¼ë¬¸ì˜ ì¸ìš© ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘...")
    seed_citation_sets = []
    
    for idx in valid_seed_indices:
        pid = paper_ids[idx]
        citations = fetch_paper_citations(pid, limit=limit)
        
        if citations:
            seed_citation_sets.append(set(citations))
            st.caption(f"   âœ“ ì‹œë“œ ë…¼ë¬¸ {idx+1}: {len(citations)}ê°œ ì¸ìš© ë°œê²¬")
        else:
            seed_citation_sets.append(set())
            st.caption(f"   âœ— ì‹œë“œ ë…¼ë¬¸ {idx+1}: ì¸ìš© ì •ë³´ ì—†ìŒ")
    
    # ëª¨ë“  ì‹œë“œì˜ ì¸ìš© ì§‘í•©ì´ ë¹„ì–´ìˆìœ¼ë©´ ì¢…ë£Œ
    if all(len(s) == 0 for s in seed_citation_sets):
        st.warning("âš ï¸ ì‹œë“œ ë…¼ë¬¸ë“¤ì˜ ì¸ìš© ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ê³µë™ì¸ìš© ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return np.zeros(len(paper_ids))
    
    # 3ë‹¨ê³„: ëª¨ë“  í›„ë³´ ë…¼ë¬¸ì˜ ì¸ìš© ì •ë³´ ìˆ˜ì§‘
    st.info(f"ğŸ” {len(paper_ids)}ê°œ í›„ë³´ ë…¼ë¬¸ì˜ ì¸ìš© ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘...")
    all_citation_sets = []
    
    for idx, pid in enumerate(paper_ids):
        if pid:
            # ì‹œë“œ ë…¼ë¬¸ì€ ì´ë¯¸ ìˆ˜ì§‘í–ˆìœ¼ë¯€ë¡œ ì¬ì‚¬ìš©
            if idx in valid_seed_indices:
                seed_idx = valid_seed_indices.index(idx)
                all_citation_sets.append(seed_citation_sets[seed_idx])
            else:
                citations = fetch_paper_citations(pid, limit=limit)
                all_citation_sets.append(set(citations) if citations else set())
        else:
            all_citation_sets.append(set())
        
        # ì§„í–‰ìƒí™© í‘œì‹œ (10ê°œë§ˆë‹¤)
        if (idx + 1) % 10 == 0:
            st.caption(f"   ì²˜ë¦¬ ì¤‘: {idx+1}/{len(paper_ids)}")
    
    # 4ë‹¨ê³„: ê° í›„ë³´ ë…¼ë¬¸ê³¼ ì‹œë“œ ë…¼ë¬¸ë“¤ ê°„ì˜ ê³µë™ì¸ìš© ìœ ì‚¬ë„ ê³„ì‚°
    scores = []
    
    for i in range(len(paper_ids)):
        candidate_set = all_citation_sets[i]
        
        if not candidate_set:
            scores.append(0.0)
            continue
        
        # ì‹œë“œ ë…¼ë¬¸ë“¤ê³¼ì˜ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
        similarities = []
        for seed_idx in valid_seed_indices:
            if seed_idx == i:  # ìê¸° ìì‹ ì€ ì œì™¸
                continue
                
            seed_set = all_citation_sets[seed_idx]
            if not seed_set:
                continue
            
            # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
            intersection = len(candidate_set & seed_set)
            union = len(candidate_set | seed_set)
            
            if union > 0:
                if similarity_metric == "cosine":
                    sim = intersection / np.sqrt(len(candidate_set) * len(seed_set))
                else:  # jaccard
                    sim = intersection / union
                similarities.append(sim)
        
        # í‰ê·  ìœ ì‚¬ë„
        avg_sim = float(np.mean(similarities)) if similarities else 0.0
        scores.append(avg_sim)
    
    # 5ë‹¨ê³„: ì •ê·œí™” (0-1 ë²”ìœ„)
    scores = np.array(scores)
    max_score = scores.max()
    
    if max_score > 0:
        scores = scores / max_score
        st.success(f"âœ“ ê³µë™ì¸ìš© ë¶„ì„ ì™„ë£Œ! (ìµœëŒ€ ìœ ì‚¬ë„: {max_score:.4f})")
    else:
        st.warning("âš ï¸ ìœ ì˜ë¯¸í•œ ê³µë™ì¸ìš© íŒ¨í„´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
    return scores

# ========================================
# ì¶”ì²œ ì ìˆ˜ ê³„ì‚° (2ë‹¨ê³„ í•„í„°ë§ ë°©ì‹)
# ========================================
def calculate_recommendation_score(papers_df, query_embedding, top_n=10, use_two_stage=True):
    """
    use_two_stage=True: 50ê°œ ìˆ˜ì§‘ â†’ ì¸ìš© ê¸°ë°˜ í•„í„°ë§ â†’ 15ê°œë¡œ ì••ì¶• â†’ ì •ë°€ ë¶„ì„
    use_two_stage=False: ê¸°ì¡´ ë°©ì‹ (30ê°œ ëª¨ë‘ ë¶„ì„)
    """
    papers_df = papers_df.copy()
    papers_df["abstract"] = papers_df["abstract"].fillna("").astype(str)
    
    # ì„ë² ë”© ê³„ì‚°
    texts = papers_df["title"].astype(str) + ". " + papers_df["abstract"].astype(str)
    embeddings = model.encode(texts.tolist())
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    semantic_scores = cosine_similarity([query_embedding], embeddings)[0]
    
    # ============================================================
    # 1ë‹¨ê³„: ë¹ ë¥¸ í•„í„°ë§ (ì¸ìš©ìˆ˜ + ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ë¡œ í›„ë³´ ì••ì¶•)
    # ============================================================
    if use_two_stage and len(papers_df) > 15:
        st.info("ğŸ” 1ë‹¨ê³„: ì¸ìš©ìˆ˜ ê¸°ë°˜ ì‚¬ì „ í•„í„°ë§ ì¤‘...")
        
        # Semantic Scholar ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë¹ ë¥¸ í•„í„°ë§ìš©)
        quick_citation_scores = []
        for idx, row in papers_df.iterrows():
            info = fetch_semanticscholar_info(title=row["title"], arxiv_id=row["arxiv_id"])
            citation_count = info["citation_count"]
            quick_citation_scores.append(citation_count)
        
        # ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ + ì¸ìš©ìˆ˜ë¡œ 1ì°¨ ì ìˆ˜ ê³„ì‚°
        quick_citation_scores = np.array(quick_citation_scores)
        normalized_citations = quick_citation_scores / (quick_citation_scores.max() + 1)
        
        normalized_semantic = semantic_scores / (semantic_scores.max() + 0.001)
        
        # 1ì°¨ ì ìˆ˜: ì˜ë¯¸ + ì¸ìš©
        quick_scores = 0.8 * normalized_semantic + 0.2 * normalized_citations
        
        # ìƒìœ„ 15ê°œë§Œ ì„ íƒ (ì •ë°€ ë¶„ì„ ëŒ€ìƒ)
        top_15_idx = np.argsort(quick_scores)[::-1][:15]
        papers_df = papers_df.iloc[top_15_idx].reset_index(drop=True)
        semantic_scores = semantic_scores[top_15_idx]
        embeddings = embeddings[top_15_idx]
        
        st.success(f"âœ“ ìƒìœ„ 15ê°œ í›„ë³´ë¡œ ì••ì¶• ì™„ë£Œ (ì¸ìš©ìˆ˜ ë²”ìœ„: {quick_citation_scores[top_15_idx].min():.0f}~{quick_citation_scores[top_15_idx].max():.0f}íšŒ)")
    
    # ============================================================
    # 2ë‹¨ê³„: ì •ë°€ ë¶„ì„ (ê³µë™ì¸ìš© í¬í•¨)
    # ============================================================
    st.info("ğŸ” 2ë‹¨ê³„: ì •ë°€ ë¶„ì„ ì‹œì‘...")
    
    # Semantic Scholar ì •ë³´ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ í™œìš©)
    citation_scores = []
    recency_scores = []
    ss_info_list = []
    paper_ids = []
    
    for idx, row in papers_df.iterrows():
        info = fetch_semanticscholar_info(title=row["title"], arxiv_id=row["arxiv_id"]) 
        ss_info_list.append(info)
        paper_ids.append(info["paper_id"])
        
        citation_count = info["citation_count"]
        citation_score = min(citation_count / 100, 1.0) if citation_count > 0 else 0
        citation_scores.append(citation_score)
        
        # ìµœì‹ ì„± ì ìˆ˜
        pub_date = datetime.strptime(row["published"], "%Y-%m-%d")
        days_old = (datetime.now() - pub_date).days
        recency_score = max(1 - (days_old / 3650), 0)
        recency_scores.append(recency_score)
    
    # ê³µë™ ì¸ìš© ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
    st.divider()
    co_citation_scores = build_co_citation_scores(
        paper_ids, limit=100, similarity_metric="jaccard", seed_window=5
    )
    
    # ìµœì¢… ì ìˆ˜ ê³„ì‚°
    citation_scores = np.array(citation_scores)
    recency_scores = np.array(recency_scores)
    co_citation_scores = np.array(co_citation_scores)
    
    # semantic_scores ì •ê·œí™”
    if semantic_scores.max() > 0:
        normalized_semantic = semantic_scores / semantic_scores.max()
    else:
        normalized_semantic = semantic_scores
    
    # ìµœì¢… ê°€ì¤‘ì¹˜: ì˜ë¯¸ + ì¸ìš© + ìµœì‹ ì„± + ê³µë™ì¸ìš©
    final_scores = (
        0.70 * normalized_semantic
        + 0.10 * citation_scores
        + 0.10 * recency_scores
        + 0.10 * co_citation_scores
    )
    
    top_idx = np.argsort(final_scores)[::-1][:top_n]
    result_df = papers_df.iloc[top_idx].reset_index(drop=True)
    result_scores = final_scores[top_idx]
    semantic_sim = semantic_scores[top_idx]
    citations = [citation_scores[i] for i in top_idx]
    recency = [recency_scores[i] for i in top_idx]
    co_citation = [co_citation_scores[i] for i in top_idx]
    
    # ê²°ê³¼ì— ì¶”ê°€ ì •ë³´ í¬í•¨
    result_df["citation_count"] = [ss_info_list[i]["citation_count"] for i in top_idx]
    result_df["found_by"] = [ss_info_list[i]["found_by"] for i in top_idx]
    result_df["co_citation_score"] = co_citation
    
    return result_df, result_scores, semantic_sim, citations, recency, co_citation

# ========================================
# LLM ì„¤ëª… ìƒì„±
# ========================================
def generate_recommendation_explanation(user_query, recommended_papers):
    papers_info = ""
    for idx, row in recommended_papers.iterrows():
        co_citation_info = f"\nCo-citation Score: {row.get('co_citation_score', 0):.3f}" if row.get('co_citation_score', 0) > 0 else ""
        
        papers_info += f"\n---\nPaper {idx+1}: {row['title']}\nAuthors: {row['authors']}\nPublished: {row['published']}\nCitations: {row.get('citation_count', 0)}{co_citation_info}\nAbstract: {row['abstract'][:300]}...\n"
    
    prompt = f"""The user is interested in the following field: "{user_query}"

Analyze the abstracts of the recommended papers below. The 'Co-citation Score' reflects how frequently the candidate is cited together with the seed papers across the literature. Provide a concise abstract summary and a professional explanation of why the paper was recommended.

The output MUST be in Korean and strictly follow the format below. Separate the analysis of each paper using the exact phrase: ###END_OF_PAPER_ANALYSIS###

{papers_info}

Format:
- ì´ˆë¡ ìš”ì•½ [N]: [ê°„ë‹¨í•œ ì„¤ëª…] \n
- ë…¼ë¬¸ ì¶”ì²œ ê·¼ê±° [N]: [ê°„ë‹¨í•œ ì„¤ëª…]
###END_OF_PAPER_ANALYSIS###
"""
    
    try:
        message = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1024,
            temperature=0.7,
        )
        return message.choices[0].message.content
    except Exception as e:
        return f"LLM ì„¤ëª… ìƒì„± ì˜¤ë¥˜: {str(e)}"

# ========================================
# ì±—ë´‡ ì…ë ¥ ì²˜ë¦¬
# ========================================
def chat_with_user(user_input):
    # ğŸŸ¢ Step 1. ì…ë ¥ì„ ì˜ì–´ë¡œ ë²ˆì—­
    user_input_en = to_english(user_input)

    with st.spinner("ì§€ê¸ˆ arXivì—ì„œ ê´€ë ¨ ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        # ğŸŸ¢ Step 2. ì˜ì–´ ë²ˆì—­ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰
        papers_df = fetch_arxiv_papers(user_input_en, max_results=50)

    if papers_df.empty:
        response = "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì£¼ì œì˜ ë…¼ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.rerun()
        return

    # ğŸŸ¢ Step 3. ì˜ì–´ ì¿¼ë¦¬ë¡œ ì„ë² ë”© ê³„ì‚°
    query_embedding = model.encode(user_input_en)

    with st.spinner("ì§€ê¸ˆ Semantic Scholarì—ì„œ ì¸ìš© ì •ë³´ ë° ê³µë™ì¸ìš© ë¶„ì„ ì¤‘..."):
        rec_papers, scores, semantic_sim, citations, recency, co_citation = (
            calculate_recommendation_score(papers_df, query_embedding, top_n=5)
        )

    with st.spinner("ì§€ê¸ˆ LLMì´ ì¶”ì²œ ì´ìœ ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        explanation = generate_recommendation_explanation(user_input, rec_papers)

    # ğŸŸ¢ Step 4. ì•ˆë‚´ ë¬¸êµ¬ì— ë²ˆì—­ ë‚´ìš© í‘œì‹œ
    response = (
        f"**'{user_input}'** â†’ **'{user_input_en}'**(ì˜ì–´ ë²ˆì—­)ìœ¼ë¡œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\n"
        f"ê´€ë ¨ ì¶”ì²œ ë…¼ë¬¸ {len(rec_papers)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”."
    )

    st.session_state.messages.append({"role": "assistant", "content": response})

    # ê²°ê³¼ ì €ì¥ ë° í™”ë©´ ê°±ì‹ ì€ ë™ì¼
    st.session_state.last_papers = rec_papers
    st.session_state.last_scores = scores
    st.session_state.last_semantic_sim = semantic_sim
    st.session_state.last_citations = citations
    st.session_state.last_recency = recency
    st.session_state.last_co_citation = co_citation
    st.session_state.last_explanation = explanation

    st.rerun()

# ========================================
# UI ë ˆì´ì•„ì›ƒ
# ========================================

message_count = len(st.session_state.messages)
if message_count > 0:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

user_query = st.chat_input("ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ë‚˜ ë…¼ë¬¸ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

if user_query:
    st.session_state.messages.append({"role": "user", "content": user_query})
    chat_with_user(user_query)

# ìµœì‹  ì¶”ì²œ ë…¼ë¬¸ ìƒì„¸ ì •ë³´
if st.session_state.last_papers is not None and not st.session_state.last_papers.empty:
    rec_papers = st.session_state.last_papers
    scores = st.session_state.last_scores
    semantic_sim = st.session_state.last_semantic_sim
    citations = st.session_state.last_citations
    recency = st.session_state.last_recency
    co_citation = st.session_state.last_co_citation
    
    st.divider()
    st.subheader("ìµœì‹  ì¶”ì²œ ë…¼ë¬¸ ìƒì„¸ ì •ë³´")
    
    for idx, row in rec_papers.iterrows():
        with st.expander(f"**{idx+1}. {row['title']}**"):
            col1, col2 = st.columns([2, 1])
            with col1:
                st.write(f"**ì €ì:** {row['authors']}")
                st.write(f"**ë°œí‘œì¼:** {row['published']}")
                st.write(f"**arXiv ID:** {row['arxiv_id']}")
                if row.get('doi'):
                    st.write(f"**DOI:** {row['doi']}")
                st.write(f"**ì¸ìš©ìˆ˜:** {row.get('citation_count', 0)}íšŒ")
                st.write(f"**ê²€ìƒ‰ë°©ë²•:** {row.get('found_by', 'N/A')}")
                st.write(f"\n**ì´ˆë¡:**\n{row['abstract']}")
            with col2:
                st.metric("ì¶”ì²œ ì ìˆ˜", f"{scores[idx]:.3f}")
                st.metric("ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„", f"{semantic_sim[idx]:.3f}")
                st.metric("ì¸ìš© ê¸°ë°˜ ì ìˆ˜", f"{citations[idx]:.3f}")
                st.metric("ìµœì‹ ì„± ì ìˆ˜", f"{recency[idx]:.3f}")
                st.metric("ê³µë™ ì¸ìš© ì ìˆ˜", f"{co_citation[idx]:.3f}",
                        help="ì‹œë“œ ë…¼ë¬¸ë“¤ê³¼ í•¨ê»˜ ì¸ìš©ë˜ëŠ” ë¹ˆë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°í•œ ìœ ì‚¬ë„ì…ë‹ˆë‹¤.")
            
            paper_url = f"https://arxiv.org/abs/{row['arxiv_id']}"
            st.markdown(f"[arXivì—ì„œ ë³´ê¸°]({paper_url})")

# LLM ë¶„ì„ ê²°ê³¼
if st.session_state.last_explanation:
    st.divider()
    st.subheader("ìµœì‹  LLM ë…¼ë¬¸ ì´ˆë¡ ìš”ì•½ ë° ì¶”ì²œ ë¶„ì„")
    
    analysis_parts = st.session_state.last_explanation.split("###END_OF_PAPER_ANALYSIS###")
    
    for i, part in enumerate(analysis_parts):
        cleaned_part = part.strip()
        if cleaned_part:
            if i > 0:
                st.divider()
>>>>>>> ddc311f (first commit)
            st.markdown(cleaned_part)